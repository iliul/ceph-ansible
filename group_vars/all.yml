---
# Variables here are applicable to all host groups NOT roles

# This sample file generated by generate_group_vars_sample.sh

# Dummy variable to avoid error because ansible does not recognize the
# file as a good configuration file when no variable in it.
dummy:

# You can override vars by using host or group vars

###########
# GENERAL #
###########

######################################
# Releases name to number dictionary #
######################################
#ceph_release_num:
#  dumpling: 0.67
#  emperor: 0.72
#  firefly: 0.80
#  giant: 0.87
#  hammer: 0.94
#  infernalis: 9
#  jewel: 10
#  kraken: 11
#  luminous: 12
#  mimic: 13
#  nautilus: 14
#  dev: 99

# Directory to fetch cluster fsid, keys etc...
fetch_directory: fetch/

cluster: ceph

# Inventory host group variables
mon_group_name: mons
osd_group_name: osds
mgr_group_name: mgrs
client_group_name: clients

############
# PACKAGES #
############
debian_package_dependencies:
  - python-pycurl

ntp_service_enabled: true

ntp_daemon_type: ntpd

bootstrap_dirs_owner: "64045"
bootstrap_dirs_group: "64045"

upgrade_ceph_packages: False


###########
# INSTALL #
###########

ceph_origin: repository
ceph_repository: community
ceph_mirror: http://download.ceph.com
ceph_stable_key: https://download.ceph.com/keys/release.asc
ceph_stable_release: luminous
ceph_stable_repo: "{{ ceph_mirror }}/debian-{{ ceph_stable_release }}"


######################
# CEPH CONFIGURATION #
######################

## Ceph options

generate_fsid: true

cephx: true

## OSD options

public_network: "172.16.16.0/24"
cluster_network: "172.31.16.0/24"
monitor_interface: bond0
osd_objectstore: bluestore

###################
# CONFIG OVERRIDE #
###################

ceph_conf_overrides:
  global:
    auth_supported : cephx
    auth_cluster_required : cephx
    auth_service_required : cephx
    auth_client_required : cephx
    public_addr : "{{ ansible_bond0['ipv4']['address'] }}" 
    cluster_addr : "{{ ansible_bond1['ipv4']['address'] }}"
    mon_osd_nearfull_ratio : 0.85
    mon_osd_full_ratio : 0.95
    mon_osd_down_out_interval : 3600
    mon_clock_drift_allowed : 0.15
    ms_type : async
    ms_async_op_threads : 4
    journal_aio : true
    journal_dio : true
    journal_force_aio : true
    journal_force_dio : true
    journal_queue_max_ops : 50000
    journal_max_write_entries : 10000
    journal_max_write_bytes : 1073741824
    debug_tp : 0
    debug_timer : 0
    debug_throttle : 0
    debug_rgw : 0
    debug_rbd : 0
    debug_rados : 0
    debug_perfcounter : 0
    debug_paxos : 0
    debug_osd : 0
    debug_optracker : 0
    debug_objecter : 0
    debug_objectcacher : 0
    debug_objclass : 0
    debug_ms : 0
    debug_monc : 0
    debug_mon : 0
    debug_mds_migrator : 0
    debug_mds_log_expire : 0
    debug_mds_log : 0
    debug_mds_locker : 0
    debug_mds_balancer : 0
    debug_mds : 0
    debug_lockdep : 0
    debug_journaler : 0
    debug_journal : 0
    debug_hadoop : 0
    debug_finisher : 0
    debug_filestore : 0
    debug_filer : 0
    debug_crush : 0
    debug_context : 0
    debug_client : 0
    debug_civetweb : 0
    debug_buffer : 0
    debug_auth : 0
    debug_asok : 0
  osd:
    osd_mount_options_xfs : "rw,noatime,nobarrier,attr2,inode64,noquota,logbsize=256k,logbufs=8,allocsize=4M"
    osd_client_message_cap : 2000
    osd_op_threads : 8
    osd_disk_threads : 1
    osd_recovery_max_active : 1
    osd_recovery_threads : 1
    osd_max_backfills : 1
    osd_client_op_priority : 50
    osd_recovery_op_priority : 10
    osd_crush_chooseleaf_type : 1
    osd_pool_default_size : 2
    osd_pool_default_min_size : 1
    osd_pool_default_pg_num : 128
    osd_pool_default_pgp_num : 128
    osd_client_message_size_cap : 1073741824
    osd_client_message_cap : 200
    osd_op_threads : 4
    osd_op_thread_timeout : 360
    osd_max_scrubs : 1
    osd_scrub_begin_hour : 1
    osd_scrub_end_hour : 6
    osd_scrub_load_threshold : 0.5
    osd_scrub_min_interval : 86400
    osd_scrub_max_interval : 604800
    osd_deep_scrub_interval : 604800
    osd_pool_erasure_code_stripe_width : 65536
    osd_pool_default_erasure_code_profile : "plugin=isa technique=reed_sol_van k=4 m=2 ruleset-root=default crush-failure-domain=host"
  filestore:
    filestore_op_threads : 4
    filestore_queue_max_ops : 1000
    filestore_queue_max_bytes : 1073741824
    filestore_op_thread_timeout : 360
    filestore_op_thread_suicide_timeout : 1080
    filestore_flusher : false
    filestore_journal_writeahead : true
    filestore_op_threads : 16
    filestore_queue_max_ops : 25000
    filestore_queue_max_bytes : 10485760
    filestore_queue_committing_max_ops : 5000
    filestore_queue_committing_max_bytes : 10485760000
    filestore_max_sync_interval : 30
    filestore_min_sync_interval : 29
    filestore_wbthrottle_xfs_ios_start_flusher : 10000
    filestore_wbthrottle_xfs_ios_hard_limit : 10000
    filestore_wbthrottle_xfs_inodes_start_flusher : 10000
    filestore_wbthrottle_xfs_inodes_hard_limit : 10000
    bluestore_block_create: true
    bluestore_block_db_size: 193273528320
    bluestore_block_db_create: true
    bluestore_block_wal_size: 4294967296
    bluestore_block_wal_create: true

os_tuning_params:
  - { name: kernel.pid_max, value: 4194303 }
  - { name: kernel.panic, value: 20 }
  - { name: kernel.hung_task_panic, value: 0 }
  - { name: kernel.hung_task_timeout_secs, value: 120 }
  - { name: kernel.threads-max, value: 1000000 }
  - { name: fs.file-max, value: 26234859 }
  - { name: vm.zone_reclaim_mode, value: 2 }
  - { name: vm.swappiness, value: 0 }
  - { name: vm.min_free_kbytes, value: 4194303 }
  - { name: vm.extra_free_kbytes, value: 4194303 }

